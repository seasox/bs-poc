{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3557aaf",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b682cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"../\"\n",
    "#base = \"../victims/sphincsplus/ref/\"\n",
    "keys_file = base + \"keys.txt\"\n",
    "sigs_file = base + \"sigs.txt\"\n",
    "faulty_sigs_file = base + \"sigs_faulty.txt\"\n",
    "\n",
    "params = 'SLH-DSA-SHAKE-256s'\n",
    "\n",
    "sanity_check = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036914a7",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Install dependencies, define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e301996",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3458976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fips205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_adrs(adrs: fips205.ADRS, end='\\n', verbose=False):\n",
    "    hex = adrs.adrs().hex()\n",
    "    if verbose:\n",
    "        print('LAYER' + ' ' * 4 + \n",
    "              'TREE ADDR' + ' ' * 18 +\n",
    "              'TYP' + ' ' * 6 +\n",
    "              'KADR' + ' ' * 5 +\n",
    "              'PADD = 0')\n",
    "    print(' '.join([hex[i:i+8] for i in range(0, len(hex), 8)]), end=' ')\n",
    "    print(end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548dc342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def process_sig(args):\n",
    "    params, pk, sig, sig_len = args\n",
    "    slh = fips205.SLH_DSA(params)\n",
    "    m = sig[sig_len:]\n",
    "    sig = sig[:sig_len]\n",
    "    valid = slh.slh_verify_internal(m, sig, pk)\n",
    "    for _, keys in slh.wots_keys.items():\n",
    "        for key in keys:\n",
    "            key.valid = valid\n",
    "    return slh.wots_keys\n",
    "\n",
    "def group_keys_by_addr(pk: bytes, sigs: list[bytes]) -> dict[fips205.ADRS, set[fips205.WOTSKeyData]]:\n",
    "    # Initialize variables\n",
    "    slh = fips205.SLH_DSA(params)\n",
    "    a = slh.a\n",
    "    d = slh.d\n",
    "    hp = slh.hp\n",
    "    n = slh.n\n",
    "    k = slh.k\n",
    "    wots_len = slh.len\n",
    "    wots_bytes = wots_len * n\n",
    "    xmss_bytes = hp * n\n",
    "    fors_bytes = k*(n + a * n)\n",
    "    sig_len = n + fors_bytes + d * (wots_bytes + xmss_bytes)\n",
    "\n",
    "    #print(\"WOTS bytes:\", wots_bytes)\n",
    "    #print(\"XMSS bytes:\", xmss_bytes)\n",
    "    #print(\"FORS bytes:\", fors_bytes)\n",
    "\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        args = [(params, pk, sig, sig_len) for sig in sigs]\n",
    "        results = pool.map(process_sig, args)\n",
    "\n",
    "    # Merge results\n",
    "    merged = {}\n",
    "    for item in results:\n",
    "        merged = merge_groups(merged, item)\n",
    "    return merged\n",
    "\n",
    "def merge_groups(left: dict[fips205.ADRS, set], right: dict[fips205.ADRS, set]) -> dict[fips205.ADRS, set]:\n",
    "    for key, items in right.items():\n",
    "        if key not in left:\n",
    "            left[key] = set()\n",
    "        left[key] = left[key] | items\n",
    "    return left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b51cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_groups(groups: dict[fips205.ADRS, list[fips205.WOTSKeyData]]):\n",
    "    print(f\"Found {len(groups)} unique addresses\")\n",
    "    faulted = [(adrs, value) for adrs, value in groups.items() if False in [v.valid for v in value]]\n",
    "    print(f\"Found {len(faulted)} groups with faulty keys\")\n",
    "    collisions = [(adrs, value) for adrs, value in faulted if len(value) > 1]\n",
    "    N = len(faulted)\n",
    "    K = 256\n",
    "    expected_collisions = (N*(N-1))/(2*K)\n",
    "    print(f\"Found {len(collisions)} groups with collisions (expected: {expected_collisions})\")\n",
    "    collisions: list[tuple[fips205.ADRS, fips205.WOTSKeyData]] = [(adrs, value) for adrs, value in collisions if True in [v.valid for v in value] and False in [v.valid for v in value]]\n",
    "    print(f\"Found {len(collisions)} groups with at least one valid and one invalid key\")\n",
    "    collisions = [\n",
    "        (adrs, value)\n",
    "        for adrs, value in collisions\n",
    "        if any(v1.msg != v2.msg and v1.pk == v2.pk for v1 in value for v2 in value if v1.valid and not v2.valid)\n",
    "    ]\n",
    "    print(f\"Found {len(collisions)} groups where at least one valid and one invalid key share the same pk\")\n",
    "\n",
    "    # sort by validity for display\n",
    "    collisions: dict[fips205.ADRS, list[fips205.WOTSKeyData]] = {adrs: sorted(value, key=lambda v: v.valid, reverse=True) for adrs, value in collisions}\n",
    "    groups = dict(sorted(groups.items(), key=lambda item: item[0].get_layer_address()))\n",
    "    for adrs, value in groups.items():\n",
    "        print_adrs(adrs, end='', verbose=True)\n",
    "        print(len(value))\n",
    "        pks = []\n",
    "        for v in value:\n",
    "            print(\"Valid\" if v.valid else \"Invalid\", end='\\t')\n",
    "            print(v.sig.hex())\n",
    "            print('\\t', end='')\n",
    "            print(v.pk.hex())\n",
    "            print('\\t', end='')\n",
    "            for chain_idx in v.msg:\n",
    "                print(f\"{chain_idx}\", end=' ')\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdc87e",
   "metadata": {},
   "source": [
    "# Clean Start\n",
    "\n",
    "Run this cell (and below) for a clean analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sigs = 0\n",
    "groups: dict[fips205.ADRS, set[fips205.WOTSKeyData]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5267d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load keys\n",
    "with open(keys_file, \"r\") as f:\n",
    "    lines = [s.split(': ') for s in f.readlines()]\n",
    "    keys = {s[0]: bytes.fromhex(s[1].strip()) for s in lines}\n",
    "sk = keys['sk']\n",
    "pk = keys['pk']\n",
    "pk.hex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3e337",
   "metadata": {},
   "source": [
    "# Load real signatures\n",
    "\n",
    "This loads the real signatures from `sigs_file` (see config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b562188",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sigs_file, \"r\") as f:\n",
    "    sigs = [bytes.fromhex(s.strip()) for s in f.readlines()]\n",
    "print(f\"Loaded {len(sigs)} signatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68c8f9",
   "metadata": {},
   "source": [
    "# Tooling sanity check\n",
    "\n",
    "This section tries to generate a signature using the same key and randomization values as the first signature in `sigs_file`.\n",
    "We expect them to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "    slh_dsa = fips205.SLH_DSA(params)\n",
    "    (_, n, h, d, hp, a, k, lgw, m) = fips205.SLH_DSA_PARAM[params]\n",
    "    wots_len = slh_dsa.len\n",
    "    wots_bytes = wots_len * n\n",
    "    xmss_bytes = hp * n\n",
    "    fors_bytes = k*(n + a * n)\n",
    "    sig_len = n + fors_bytes + d * (wots_bytes + xmss_bytes)\n",
    "\n",
    "    sig = sigs[0]\n",
    "\n",
    "    m = sig[sig_len:]\n",
    "    r = sig[:n]\n",
    "    pysig = slh_dsa.slh_sign_internal(m, sk, None, r=r)\n",
    "    pysig += m\n",
    "\n",
    "    if pysig != sig:\n",
    "        print(\"Signature mismatch\")\n",
    "        print(pysig.hex())\n",
    "        print(sig.hex())\n",
    "    print(\"Passed sanity check\")\n",
    "else:\n",
    "    print(\"Skipping sanity check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df11a2",
   "metadata": {},
   "source": [
    "# Update Experiment\n",
    "Run this cell (and below) to process new signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if processed_sigs > 0:\n",
    "    print(f\"Skipping {processed_sigs} signatures\")\n",
    "\n",
    "sigs = sigs[processed_sigs:]\n",
    "\n",
    "print(f\"Processing {len(sigs)} signatures...\", end=' ')\n",
    "\n",
    "groups = merge_groups(groups, group_keys_by_addr(pk, sigs))\n",
    "\n",
    "print(f\"done!\")\n",
    "\n",
    "# update processed_sigs for consecutive runs\n",
    "processed_sigs += len(sigs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ad55a2",
   "metadata": {},
   "source": [
    "# Load simulated faults\n",
    "This section loads simulated faults from `faulty_sigs_file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9629c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(faulty_sigs_file, \"r\") as f:\n",
    "    faulty_sigs = [bytes.fromhex(s.strip()) for s in f.readlines()]\n",
    "    #sigs = [(s[0], bytes.fromhex(s[1])) for s in sigs]\n",
    "    #sigs_correct = [s[1] for s in sigs if s[0] == '[CORRECT]']\n",
    "    #sigs_faulty = [s[1] for s in sigs if s[0] == '[FAULTY]']\n",
    "print(f\"Loaded {len(faulty_sigs)} faulty (simulated) signatures\")\n",
    "simulated_groups = group_keys_by_addr(pk, faulty_sigs)\n",
    "groups = merge_groups(groups, simulated_groups)\n",
    "print_groups(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c08d3f2",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "...appear here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b753b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_groups(groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
