{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e301996",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b682cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"../\"\n",
    "#base = \"../victims/sphincsplus/ref/\"\n",
    "keys_file = base + \"keys.txt\"\n",
    "sigs_file = base + \"sigs.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3458976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fips205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_adrs(adrs: fips205.ADRS, end='\\n'):\n",
    "    hex = adrs.adrs().hex()\n",
    "    print(' '.join([hex[i:i+8] for i in range(0, len(hex), 8)]), end=' ')\n",
    "    print(end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574fa0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_keys_by_addr(self: fips205.SLH_DSA, pk: bytes, sigs: list[bytes]) -> dict[fips205.ADRS, list[fips205.WOTSKeyData]]:\n",
    "    # we assume SPHINCS-SHAKE-256s\n",
    "    a = self.a\n",
    "    d = self.d\n",
    "    hp = self.hp\n",
    "    n = self.n\n",
    "    k = self.k\n",
    "    wots_len = self.len\n",
    "    wots_bytes = wots_len * n\n",
    "    xmss_bytes = hp * n\n",
    "    fors_bytes = k*(n+a*n) # 10560\n",
    "    print(\"WOTS bytes:\", wots_bytes)\n",
    "    print(\"XMSS bytes:\", xmss_bytes)\n",
    "    print(\"FORS bytes:\", fors_bytes)\n",
    "    sig_len = n + fors_bytes + d * (wots_bytes + xmss_bytes)\n",
    "    \n",
    "    for sig in sigs:\n",
    "        m = sig[sig_len:]\n",
    "        sig = sig[:sig_len]\n",
    "        wots_keys_before = self.wots_keys.copy()\n",
    "        valid = self.slh_verify_internal(m, sig, pk)\n",
    "        wots_keys_after = self.wots_keys\n",
    "        for key, value in wots_keys_after.items():\n",
    "            old_values = wots_keys_before[key] if key in wots_keys_before else []\n",
    "            if old_values != value:\n",
    "                new_vals = [v for v in value if v not in old_values]\n",
    "                for v in new_vals:\n",
    "                    v.valid = valid\n",
    "    return self.wots_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548dc342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from copy import deepcopy\n",
    "\n",
    "def process_sig(args):\n",
    "    self_copy, pk, sig, sig_len = args\n",
    "    m = sig[sig_len:]\n",
    "    sig = sig[:sig_len]\n",
    "    wots_keys_before = deepcopy(self_copy.wots_keys)\n",
    "    valid = self_copy.slh_verify_internal(m, sig, pk)\n",
    "    wots_keys_after = self_copy.wots_keys\n",
    "\n",
    "    result = []\n",
    "    for key, value in wots_keys_after.items():\n",
    "        old_values = wots_keys_before.get(key, [])\n",
    "        if old_values != value:\n",
    "            new_vals = [v for v in value if v not in old_values]\n",
    "            for v in new_vals:\n",
    "                v.valid = valid\n",
    "            result.append((key, new_vals))\n",
    "    return result\n",
    "\n",
    "def group_keys_by_addr(self: fips205.SLH_DSA, pk: bytes, sigs: list[bytes]) -> dict[fips205.ADRS, list[fips205.WOTSKeyData]]:\n",
    "    # Initialize variables\n",
    "    a = self.a\n",
    "    d = self.d\n",
    "    hp = self.hp\n",
    "    n = self.n\n",
    "    k = self.k\n",
    "    wots_len = self.len\n",
    "    wots_bytes = wots_len * n\n",
    "    xmss_bytes = hp * n\n",
    "    fors_bytes = k*(n + a * n)\n",
    "    sig_len = n + fors_bytes + d * (wots_bytes + xmss_bytes)\n",
    "\n",
    "    print(\"WOTS bytes:\", wots_bytes)\n",
    "    print(\"XMSS bytes:\", xmss_bytes)\n",
    "    print(\"FORS bytes:\", fors_bytes)\n",
    "\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        args = [(deepcopy(self), pk, sig, sig_len) for sig in sigs]\n",
    "        results = pool.map(process_sig, args)\n",
    "\n",
    "    # Merge results\n",
    "    merged = {}\n",
    "    for item in results:\n",
    "        for key, val_list in item:\n",
    "            if key not in merged:\n",
    "                merged[key] = []\n",
    "            merged[key].extend(val_list)\n",
    "\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5267d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(keys_file, \"r\") as f:\n",
    "    lines = [s.split(': ') for s in f.readlines()]\n",
    "    keys = {s[0]: bytes.fromhex(s[1].strip()) for s in lines}\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sigs_file, \"r\") as f:\n",
    "    sigs = [bytes.fromhex(s.strip()) for s in f.readlines()]\n",
    "    #sigs = [(s[0], bytes.fromhex(s[1])) for s in sigs]\n",
    "    #sigs_correct = [s[1] for s in sigs if s[0] == '[CORRECT]']\n",
    "    #sigs_faulty = [s[1] for s in sigs if s[0] == '[FAULTY]']\n",
    "print(f\"Loaded {len(sigs)} signatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "slh_dsa = fips205.SLH_DSA('SLH-DSA-SHAKE-256s')\n",
    "pk = keys['pk']\n",
    "pk_seed = pk[:slh_dsa.n]\n",
    "pk_root = pk[slh_dsa.n:]\n",
    "groups = group_keys_by_addr(slh_dsa, keys['pk'], sigs)\n",
    "\n",
    "groups = sorted(groups.items(), key=lambda item: len(item[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b753b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "slh_dsa = fips205.SLH_DSA('SLH-DSA-SHAKE-256s')\n",
    "\n",
    "print(f\"Found {len(groups)} unique addresses\")\n",
    "faulted = [1 for _, value in groups if False in [v.valid for v in value]]\n",
    "print(f\"Found {len(faulted)} groups with faulty keys\")\n",
    "collisions = [(adrs, value) for adrs, value in groups if len(value) > 1]\n",
    "print(f\"Found {len(collisions)} groups with collisions\")\n",
    "collisions = [(adrs, value) for adrs, value in collisions if True in [v.valid for v in value] and False in [v.valid for v in value]]\n",
    "print(f\"Found {len(collisions)} groups with at least one valid and one invalid key\")\n",
    "collisions = [\n",
    "    (adrs, value)\n",
    "    for adrs, value in collisions\n",
    "    if any(v1.pk == v2.pk for v1 in value for v2 in value if v1.valid and not v2.valid)\n",
    "]\n",
    "print(f\"Found {len(collisions)} groups where at least one valid and one invalid key share the same pk\")\n",
    "# sort by validity for display\n",
    "collisions = [(adrs, sorted(value, key=lambda v: v.valid, reverse=True)) for adrs, value in collisions]\n",
    "for adrs, value in collisions:\n",
    "    # print key.hex(), add whitespace every 4 bytes\n",
    "    print_adrs(adrs, end='')\n",
    "    print(len(value))\n",
    "    pks = []\n",
    "    for v in value:\n",
    "        print(\"Valid\" if v.valid else \"Invalid\", end='\\t')\n",
    "        print(v.pk.hex())\n",
    "        print('\\t', end='')\n",
    "        for chain_idx in v.msg:\n",
    "            print(f\"{chain_idx}\", end=' ')\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
