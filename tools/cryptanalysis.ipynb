{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3557aaf",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b682cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"../\"\n",
    "#base = \"../victims/sphincsplus/ref/\"\n",
    "keys_file = base + \"keys.txt\"\n",
    "sigs_file = base + \"sigs.txt\"\n",
    "faulty_sigs_file = base + \"sigs_faulty.txt\"\n",
    "\n",
    "params = 'SLH-DSA-SHAKE-256s'\n",
    "\n",
    "sanity_check = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036914a7",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Install dependencies, define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e301996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.23.4 in /Users/jb/Documents/jobs/uni-luebeck/msc-itsec/thesis/swage/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.23.4)\n",
      "Requirement already satisfied: pycryptodome==3.16.0 in /Users/jb/Documents/jobs/uni-luebeck/msc-itsec/thesis/swage/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (3.16.0)\n",
      "Requirement already satisfied: sympy==1.11.1 in /Users/jb/Documents/jobs/uni-luebeck/msc-itsec/thesis/swage/.venv/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.11.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jb/Documents/jobs/uni-luebeck/msc-itsec/thesis/swage/.venv/lib/python3.10/site-packages (from sympy==1.11.1->-r requirements.txt (line 3)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Python 3.10.15\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3458976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fips205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "917d1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_adrs(adrs: fips205.ADRS, end='\\n', verbose=False):\n",
    "    hex = adrs.adrs().hex()\n",
    "    if verbose:\n",
    "        print('LAYER' + ' ' * 4 + \n",
    "              'TREE ADDR' + ' ' * 18 +\n",
    "              'TYP' + ' ' * 6 +\n",
    "              'KADR' + ' ' * 5 +\n",
    "              'PADD = 0')\n",
    "    print(' '.join([hex[i:i+8] for i in range(0, len(hex), 8)]), end=' ')\n",
    "    print(end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2214aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_keys_by_addr(pk: bytes, sigs: list[bytes]) -> dict[fips205.ADRS, set[fips205.WOTSKeyData]]:\n",
    "    import multiprocessing\n",
    "    from cryptanalysis_lib import process_sig\n",
    "    slh = fips205.SLH_DSA(params)\n",
    "    a = slh.a\n",
    "    d = slh.d\n",
    "    hp = slh.hp\n",
    "    n = slh.n\n",
    "    k = slh.k\n",
    "    wots_bytes = slh.len * n\n",
    "    xmss_bytes = hp * n\n",
    "    fors_bytes = k * (n + a * n)\n",
    "    sig_len = n + fors_bytes + d * (wots_bytes + xmss_bytes)\n",
    "\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        args = [(params, pk, sig, sig_len) for sig in sigs]\n",
    "        results = pool.map(process_sig, args)\n",
    "\n",
    "    # Merge results\n",
    "    merged = {}\n",
    "    for item in results:\n",
    "        merged = merge_groups(merged, item)\n",
    "    return merged\n",
    "\n",
    "def merge_groups(left: dict[fips205.ADRS, set], right: dict[fips205.ADRS, set]) -> dict[fips205.ADRS, set]:\n",
    "    for key, items in right.items():\n",
    "        if key not in left:\n",
    "            left[key] = set()\n",
    "        left[key] = left[key] | items\n",
    "    return left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b51cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_groups(groups: dict[fips205.ADRS, list[fips205.WOTSKeyData]]):\n",
    "    (_,n,_,_,_,_,_,_,_) = fips205.SLH_DSA_PARAM[params]\n",
    "    print(f\"Found {len(groups)} unique addresses\")\n",
    "    faulted = [(adrs, value) for adrs, value in groups.items() if False in [v.valid for v in value]]\n",
    "    print(f\"Found {len(faulted)} groups with faulty keys\")\n",
    "    collisions = [(adrs, value) for adrs, value in faulted if len(value) > 1]\n",
    "    N = len(faulted)\n",
    "    K = 256\n",
    "    expected_collisions = (N*(N-1))/(2*K)\n",
    "    print(f\"Found {len(collisions)} groups with collisions (expected: {expected_collisions})\")\n",
    "    collisions: list[tuple[fips205.ADRS, set[fips205.WOTSKeyData]]] = [(adrs, value) for adrs, value in collisions if any(v.valid for v in value) and not all(v.valid for v in value)]\n",
    "    print(f\"Found {len(collisions)} groups with at least one valid and one invalid key\")\n",
    "    \"\"\"collisions = [\n",
    "        (adrs, value)\n",
    "        for adrs, value in collisions\n",
    "        if any(v1.msg != v2.msg and v1.pk == v2.pk for v1 in value for v2 in value if v1.valid and not v2.valid)\n",
    "    ]\"\"\"\n",
    "    def has_shared_intermediate(v1, value):\n",
    "        return any(\n",
    "            inter in v2.sig\n",
    "            for chain in v1.intermediates\n",
    "            for inter in chain\n",
    "            for v2 in value if v2.valid\n",
    "        )\n",
    "    def find_all_shared_intermediate_offsets(v1, valid_sig):\n",
    "        results = []\n",
    "        for chain_idx, chain in enumerate(v1.intermediates):\n",
    "            for exposed_count, inter in enumerate(chain):\n",
    "                try:\n",
    "                    offset = valid_sig.sig.index(inter)\n",
    "                    results.append((chain_idx, exposed_count, offset/n))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return results\n",
    "    collisions = [\n",
    "        (adrs, value)\n",
    "        for adrs, value in collisions\n",
    "        if any(not v1.valid and has_shared_intermediate(v1, value) for v1 in value)\n",
    "    ]\n",
    "    print(f\"Found {len(collisions)} groups with exposed WOTS secrets\")\n",
    "\n",
    "    # sort by layer address\n",
    "    collisions = sorted(collisions, key=lambda item: item[0].get_layer_address())\n",
    "    for adrs, value in collisions:\n",
    "        valid_sig = [v for v in value if v.valid][0]\n",
    "        invalid_sigs = [v for v in value if not v.valid]\n",
    "        print_adrs(adrs, end='', verbose=True)\n",
    "        print(len(value))\n",
    "        \n",
    "        for v in [valid_sig] + invalid_sigs:\n",
    "            print(\"Valid\" if v.valid else \"Invalid\", end='\\t')\n",
    "            print(v.sig.hex())\n",
    "            print('\\t', end='')\n",
    "            print(v.pk.hex())\n",
    "            print('\\t', end='')\n",
    "            for chain_idx in v.msg:\n",
    "                print(f\"{chain_idx}\", end=' ')\n",
    "            print()\n",
    "            print(\"Exposed WOTS secrets: \", end='')\n",
    "            print(find_all_shared_intermediate_offsets(v, valid_sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdc87e",
   "metadata": {},
   "source": [
    "# Clean Start\n",
    "\n",
    "Run this cell (and below) for a clean analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "184c2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sigs = 0\n",
    "groups: dict[fips205.ADRS, set[fips205.WOTSKeyData]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5267d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0bc005bdb4dfb431bb250e109ca4430d42f4fd7e9270f515640701df308413952d854a500f3e893a8804ad88a600ee6812c3317e422848c5854c2b18588c1b9a'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load keys\n",
    "with open(keys_file, \"r\") as f:\n",
    "    lines = [s.split(': ') for s in f.readlines()]\n",
    "    keys = {s[0]: bytes.fromhex(s[1].strip()) for s in lines}\n",
    "sk = keys['sk']\n",
    "pk = keys['pk']\n",
    "pk.hex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3e337",
   "metadata": {},
   "source": [
    "# Load real signatures\n",
    "\n",
    "This loads the real signatures from `sigs_file` (see config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b562188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20720 signatures\n"
     ]
    }
   ],
   "source": [
    "with open(sigs_file, \"r\") as f:\n",
    "    sigs = [bytes.fromhex(s.strip()) for s in f.readlines()]\n",
    "print(f\"Loaded {len(sigs)} signatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68c8f9",
   "metadata": {},
   "source": [
    "# Tooling sanity check\n",
    "\n",
    "This section tries to generate a signature using the same key and randomization values as the first signature in `sigs_file`.\n",
    "We expect them to match. This assumes that the first signature in `sigs_file` is a valid signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a637940c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping sanity check\n"
     ]
    }
   ],
   "source": [
    "if sanity_check:\n",
    "    slh_dsa = fips205.SLH_DSA(params)\n",
    "    (_, n, h, d, hp, a, k, lgw, m) = fips205.SLH_DSA_PARAM[params]\n",
    "    wots_len = slh_dsa.len\n",
    "    wots_bytes = wots_len * n\n",
    "    xmss_bytes = hp * n\n",
    "    fors_bytes = k*(n + a * n)\n",
    "    sig_len = n + fors_bytes + d * (wots_bytes + xmss_bytes)\n",
    "\n",
    "    sig = sigs[0]\n",
    "\n",
    "    m = sig[sig_len:]\n",
    "    r = sig[:n]\n",
    "    pysig = slh_dsa.slh_sign_internal(m, sk, None, r=r)\n",
    "    pysig += m\n",
    "\n",
    "    if pysig != sig:\n",
    "        print(\"Signature mismatch\")\n",
    "        print(pysig.hex())\n",
    "        print(sig.hex())\n",
    "    print(\"Passed sanity check\")\n",
    "else:\n",
    "    print(\"Skipping sanity check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df11a2",
   "metadata": {},
   "source": [
    "# Update Experiment\n",
    "Run this cell (and below) to process new signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d60a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20720 signatures... "
     ]
    }
   ],
   "source": [
    "if processed_sigs > 0:\n",
    "    print(f\"Skipping {processed_sigs} signatures\")\n",
    "\n",
    "sigs = sigs[processed_sigs:]\n",
    "\n",
    "print(f\"Processing {len(sigs)} signatures...\", end=' ')\n",
    "\n",
    "groups = merge_groups(groups, group_keys_by_addr(pk, sigs))\n",
    "\n",
    "print(f\"done!\")\n",
    "\n",
    "# update processed_sigs for consecutive runs\n",
    "processed_sigs += len(sigs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ad55a2",
   "metadata": {},
   "source": [
    "# Load simulated faults\n",
    "This section loads simulated faults from `faulty_sigs_file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9629c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(faulty_sigs_file, \"r\") as f:\n",
    "    faulty_sigs = [bytes.fromhex(s.strip()) for s in f.readlines()]\n",
    "    #sigs = [(s[0], bytes.fromhex(s[1])) for s in sigs]\n",
    "    #sigs_correct = [s[1] for s in sigs if s[0] == '[CORRECT]']\n",
    "    #sigs_faulty = [s[1] for s in sigs if s[0] == '[FAULTY]']\n",
    "print(f\"Loaded {len(faulty_sigs)} faulty (simulated) signatures\")\n",
    "simulated_groups = group_keys_by_addr(pk, faulty_sigs)\n",
    "groups = merge_groups(groups, simulated_groups)\n",
    "print_groups(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c08d3f2",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "...appear here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b753b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_groups(groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
