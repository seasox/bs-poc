{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3557aaf",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b682cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"../\"\n",
    "#base = \"../victims/sphincsplus/ref/\"\n",
    "keys_file = base + \"keys.txt\"\n",
    "sigs_file = base + \"sigs.txt\"\n",
    "sigs_simulated_file = base + \"sigs_simulated.txt\"\n",
    "\n",
    "params = 'SLH-DSA-SHAKE-256s'\n",
    "\n",
    "sanity_check = False\n",
    "simulate_faults = False\n",
    "filter_sigs  = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036914a7",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Install dependencies, define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e301996",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3458976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fips205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6779c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "slh = fips205.SLH_DSA(params)\n",
    "a = slh.a\n",
    "d = slh.d\n",
    "hp = slh.hp\n",
    "n = slh.n\n",
    "k = slh.k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_adrs(adrs: fips205.ADRS, end='\\n', verbose=False):\n",
    "    hex = adrs.adrs().hex()\n",
    "    if verbose:\n",
    "        print('LAYER' + ' ' * 4 + \n",
    "              'TREE ADDR' + ' ' * 18 +\n",
    "              'TYP' + ' ' * 6 +\n",
    "              'KADR' + ' ' * 5 +\n",
    "              'PADD = 0')\n",
    "    print(' '.join([hex[i:i+8] for i in range(0, len(hex), 8)]), end=' ')\n",
    "    print(end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2214aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import cpu_count\n",
    "\n",
    "\n",
    "def extract_wots_keys(pk: bytes, sigs: list[bytes]) -> dict[fips205.ADRS, set[fips205.WOTSKeyData]]:\n",
    "    import multiprocessing\n",
    "    from cryptanalysis_lib import process_sig\n",
    "    wots_bytes = slh.len * n\n",
    "    xmss_bytes = hp * n\n",
    "    fors_bytes = k * (n + a * n)\n",
    "    sig_len = n + fors_bytes + d * (wots_bytes + xmss_bytes)\n",
    "\n",
    "    with multiprocessing.Pool(processes=cpu_count()-1) as pool:\n",
    "        args = [(params, pk, sig_idx, sig, sig_len) for sig_idx, sig in enumerate(sigs)]\n",
    "        results = pool.map(process_sig, args)\n",
    "    \n",
    "    # Merge results\n",
    "    merged = {}\n",
    "    for item in results:\n",
    "        merged = merge_groups(merged, item)\n",
    "    return merged\n",
    "\n",
    "def merge_groups(left: dict[fips205.ADRS, set], right: dict[fips205.ADRS, set]) -> dict[fips205.ADRS, set]:\n",
    "    for key, items in right.items():\n",
    "        if key not in left:\n",
    "            left[key] = set()\n",
    "        left[key] = left[key] | items\n",
    "    return left\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b51cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generator\n",
    "\n",
    "\n",
    "def shared_intermediates(v1: fips205.WOTSKeyData, valid: fips205.WOTSKeyData) -> Generator[tuple[int, int], None, bool]:\n",
    "    if not v1.intermediates or not valid.intermediates:\n",
    "        return False\n",
    "    if v1 == valid:\n",
    "        return False\n",
    "    retval = False\n",
    "    for chain_idx, chain in enumerate(v1.intermediates):\n",
    "        if not chain:\n",
    "            continue\n",
    "        for hash_iter, step in enumerate(chain[1:], start=1):\n",
    "            if step == valid.sig[chain_idx*n:(chain_idx+1)*n]:\n",
    "                retval = True\n",
    "                yield (chain_idx, hash_iter)\n",
    "    return retval\n",
    "    \n",
    "\n",
    "def find_collisions(wots_sigs: dict[fips205.ADRS, set[fips205.WOTSKeyData]]) -> dict[fips205.ADRS, set[fips205.WOTSKeyData]]:\n",
    "    return {adrs: keys for adrs, keys in wots_sigs.items() if len(keys) > 1}\n",
    "\n",
    "def print_arr_w(arr: list[int], width=int):\n",
    "    print('[ ', end='')\n",
    "    for x in arr:\n",
    "        print(f\"{x:0{width}d}\", end=' ')\n",
    "    print(']')\n",
    "    \n",
    "def valid_sigs_d(groups):\n",
    "    return {adrs: key for adrs, keys in groups.items() for key in keys if key.valid}\n",
    "\n",
    "def hex(s: bytes | None) -> str:\n",
    "    return s.hex() if s else \"None\"\n",
    "\n",
    "def print_key_data(v: fips205.WOTSKeyData, adrs: fips205.ADRS, pk_seed: bytes, valid_key: fips205.WOTSKeyData = None, indent=''):\n",
    "    print(indent + (\"Valid\" if v.valid else \"Invalid\" if v.valid == False else \"--\"), end='\\t')\n",
    "    print(indent + v.sig.hex()[:128] + '...')\n",
    "    print(indent + '\\tPK (from tree)\\t' + hex(v.pk))\n",
    "    pk = v.calculate_pk(params, adrs, pk_seed)\n",
    "    print(indent + '\\tPK (calculated)\\t' + hex(pk))\n",
    "    print(indent + f\"\\tWOTS key is part of signature {v.sig_idx}\")\n",
    "    print(indent + '\\t\\t\\t', end='')\n",
    "    print_arr_w([i for i in range(len(v.chains))], 2)\n",
    "    print(indent + '\\t' + \"chains\\t\\t\", end='')\n",
    "    print_arr_w(v.chains, 2)\n",
    "    print(indent + '\\t' + \"chains (calc)\\t\", end = '')\n",
    "    print_arr_w(v.chains_calculated, 2)\n",
    "    if valid_key and not v.valid:\n",
    "        for chain_idx, exposed in shared_intermediates(v, valid_key):\n",
    "            print(indent + f\"\\t\\tExposed {exposed} secret values at chain_idx {chain_idx}\")\n",
    "    \n",
    "\n",
    "def print_groups(pk_seed: bytes, groups: dict[fips205.ADRS, list[fips205.WOTSKeyData]], skip_no_exposed=True):\n",
    "    #collisions: list[tuple[fips205.ADRS, set[fips205.WOTSKeyData]]] = [(adrs, value) for adrs, value in collisions if any(v.valid for v in value) and not all(v.valid for v in value)]\n",
    "    #print(f\"Found {len(collisions)} groups with at least one valid and one invalid key\")\n",
    "    # collisions where PK match. This is not necessary. Better: find exposed keys by running WOTS chain\n",
    "    \"\"\"collisions = [\n",
    "        (adrs, value)\n",
    "        for adrs, value in collisions\n",
    "        if any(v1.msg != v2.msg and v1.pk == v2.pk for v1 in value for v2 in value if v1.valid and not v2.valid)\n",
    "    ]\"\"\"\n",
    "    \n",
    "    valid_sigs = valid_sigs_d(groups)\n",
    "\n",
    "    # sort by layer address\n",
    "    groups = sorted(groups.items(), key=lambda item: item[0].get_layer_address())\n",
    "    \n",
    "    for adrs, value in groups:\n",
    "        valid_sig = valid_sigs[adrs] if adrs in valid_sigs else None\n",
    "        invalid_sigs = [v for v in value if not v.valid]\n",
    "        print_adrs(adrs, end='', verbose=True)\n",
    "        print(len(value))\n",
    "        \n",
    "        for v in [valid_sig] + invalid_sigs:\n",
    "            if not v:\n",
    "                continue\n",
    "            if skip_no_exposed and not v.valid and not shared_intermediates(v, valid_sig):\n",
    "                continue\n",
    "            print_key_data(v, adrs, pk_seed, valid_sig, indent='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cdc87e",
   "metadata": {},
   "source": [
    "# Clean Start\n",
    "\n",
    "Run this cell (and below) for a clean analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_sigs = 0\n",
    "groups: dict[fips205.ADRS, set[fips205.WOTSKeyData]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5267d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load keys\n",
    "with open(keys_file, \"r\") as f:\n",
    "    lines = [s.split(': ') for s in f.readlines()]\n",
    "    keys = {s[0]: bytes.fromhex(s[1].strip()) for s in lines}\n",
    "sk = keys['sk']\n",
    "pk = keys['pk']\n",
    "pk_seed = pk[:n]\n",
    "pk.hex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df11a2",
   "metadata": {},
   "source": [
    "# Update Experiment\n",
    "Run this cell (and below) to process new signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3e337",
   "metadata": {},
   "source": [
    "# Load real signatures\n",
    "\n",
    "This loads the real signatures from `sigs_file` (see config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b562188",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sigs_file, \"r\") as f:\n",
    "    sigs = [bytes.fromhex(s.strip()) for s in f.readlines()]\n",
    "    # sigs = sigs[:1000]\n",
    "print(f\"Loaded {len(sigs)} signatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ad55a2",
   "metadata": {},
   "source": [
    "# Load simulated faulty signatures\n",
    "This section loads simulated faults from `sigs_simulated_file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9629c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if simulate_faults and os.path.exists(sigs_simulated_file):\n",
    "    with open(sigs_simulated_file, \"r\") as f:\n",
    "        faulty_sigs = [bytes.fromhex(s.strip()) for s in f.readlines()]\n",
    "    print(f\"Loaded {len(faulty_sigs)} faulty (simulated) signatures\")\n",
    "    simulated_groups = extract_wots_keys(pk, faulty_sigs)\n",
    "    for adrs, keys in simulated_groups.items():\n",
    "        for key in keys:\n",
    "            key.simulated = True\n",
    "    print_groups(pk_seed, simulated_groups)\n",
    "    groups = merge_groups(groups, simulated_groups)\n",
    "else:\n",
    "    print(\"Fault simulation disabled or no simulated faulty signatures found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68c8f9",
   "metadata": {},
   "source": [
    "# Tooling sanity check\n",
    "\n",
    "This section tries to generate a signature using the same key and randomization values as the first signature in `sigs_file`.\n",
    "We expect them to match. This assumes that the first signature in `sigs_file` is a valid signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979dec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check:\n",
    "    wots_len = slh.len\n",
    "    wots_bytes = wots_len * n\n",
    "    xmss_bytes = hp * n\n",
    "    fors_bytes = k*(n + a * n)\n",
    "    sig_len = n + fors_bytes + d * (wots_bytes + xmss_bytes)\n",
    "\n",
    "    sig = sigs[0]\n",
    "\n",
    "    m = sig[sig_len:]\n",
    "    r = sig[:n]\n",
    "    pysig = slh.slh_sign_internal(m, sk, None, r=r)\n",
    "    pysig += m\n",
    "\n",
    "    if pysig != sig:\n",
    "        print(\"Signature mismatch\")\n",
    "        print(pysig.hex())\n",
    "        print(sig.hex())\n",
    "    print(\"Passed sanity check\")\n",
    "else:\n",
    "    print(\"Skipping sanity check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221c424",
   "metadata": {},
   "source": [
    "# Extract WOTS keys\n",
    "\n",
    "Extract all WOTS keys in all signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if processed_sigs > 0:\n",
    "    print(f\"Skipping {processed_sigs} signatures\")\n",
    "\n",
    "sigs = sigs[processed_sigs:]\n",
    "print(f\"Processing {len(sigs)} signatures...\", end=' ')\n",
    "\n",
    "groups = merge_groups(groups, extract_wots_keys(pk, sigs))\n",
    "print(f\"Found {len(groups)} unique addresses\")\n",
    "\n",
    "# update processed_sigs for consecutive runs\n",
    "processed_sigs += len(sigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c7a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # get distribution of steps in (valid) signatures\n",
    "    distr = [[0 for _ in range(16)] for _ in range(67)]\n",
    "    for adrs, keys in groups.items():\n",
    "        for key in keys:\n",
    "            if key.valid:\n",
    "                for chain_idx, chain in enumerate(key.chains):\n",
    "                        distr[chain_idx][chain] += 1           \n",
    "    distr\n",
    "\n",
    "    %pip install matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # distr is your 67×16 list of counts\n",
    "    # e.g. distr = [[…], …, […]]\n",
    "\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    plt.imshow(distr, aspect='auto')        # default colormap\n",
    "    plt.colorbar(label='Count')              # show scale\n",
    "    plt.xlabel('Step value (0–15)')\n",
    "    plt.ylabel('Chain index (0–66)')\n",
    "    plt.title('Distribution of steps in valid signatures')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c08d3f2",
   "metadata": {},
   "source": [
    "# Group Collisions\n",
    "\n",
    "...appear here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check for multiple valid keys\n",
    "for adrs, keys in groups.items():\n",
    "    if len([v for v in keys if v.valid]) > 1:\n",
    "        print(\"ERROR: found multiple valid keys for the same address\", adrs, keys)\n",
    "        raise ValueError(\"Multiple valid keys for the same address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ddcca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maintain a dictionary of valid signatures per adrs\n",
    "valid_sigs = valid_sigs_d(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep keys at layer 7\n",
    "groups = {adrs: sigs for adrs, sigs in groups.items() if adrs.get_layer_address() == 7}\n",
    "groups = {adrs: sigs for adrs, sigs in groups.items() if len(sigs) > 0}\n",
    "print(f\"Found {len(groups)} groups at layer 7\")\n",
    "\n",
    "# only keep keys where we also observered valid signatures\n",
    "groups = {adrs: sigs for adrs, sigs in groups.items() if adrs in valid_sigs}\n",
    "groups = {adrs: sigs for adrs, sigs in groups.items() if len(sigs) > 0}\n",
    "print(f\"Found {len(groups)} groups with valid signatures\")\n",
    "\n",
    "# only keep collisions\n",
    "groups = find_collisions(groups)\n",
    "print(f\"Found {len(groups)} groups with collisions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9949068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-process collided WOTS keys\n",
    "for adrs, keys in groups.items():\n",
    "    if adrs not in valid_sigs:\n",
    "        continue\n",
    "    valid_sig = valid_sigs[adrs]\n",
    "    for key in keys:\n",
    "        key.calculate_intermediates(params, adrs, pk_seed, valid_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out all-7 sigs\n",
    "all_7_indices = set()\n",
    "for adrs, keys in groups.items():\n",
    "    keys_c = keys.copy()\n",
    "    for i, key in enumerate(keys_c):\n",
    "        if all(c == 7 for c in key.chains_calculated):\n",
    "            all_7_indices.add(key.sig_idx)\n",
    "            keys.remove(key)\n",
    "            \n",
    "\n",
    "with open(\"sigs_wots7.txt\", \"w\") as f:\n",
    "    for idx in sorted(all_7_indices):\n",
    "        f.write(f\"{sigs[idx].hex()}\\n\")\n",
    "\n",
    "# filter out signatures containing no WOTS secrets\n",
    "groups = {adrs: [sig for sig in sigs if any(i < 17 for i in sig.chains_calculated)] for adrs, sigs in groups.items()}\n",
    "groups = find_collisions(groups)\n",
    "print(f\"Found {len(groups)} groups with at least one WOTS secret\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ceabcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_groups(pk_seed, groups, skip_no_exposed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b57808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_signatures(sigs: list[bytes], wots_keys: dict[fips205.ADRS, set[fips205.WOTSKeyData]]) -> set[bytes]:\n",
    "    filtered_sigs = set()\n",
    "    collisions = find_collisions(wots_keys)\n",
    "    collisions = {adrs: sigs for adrs, sigs in collisions.items() if any(sig.valid for sig in sigs) and not all(sig.valid for sig in sigs)}\n",
    "    valid_sigs = valid_sigs_d(wots_keys)\n",
    "    for adrs, keys in collisions.items():\n",
    "        for key in keys:\n",
    "            if key.valid:\n",
    "                # keep valid keys\n",
    "                filtered_sigs.add(sigs[key.sig_idx])\n",
    "            if adrs in valid_sigs and shared_intermediates(key, valid_sigs[adrs]):\n",
    "                filtered_sigs.add(sigs[key.sig_idx])\n",
    "    return filtered_sigs\n",
    "\n",
    "if filter_sigs:\n",
    "    # only keep signatures that are valid or have exposed WOTS keys\n",
    "    filtered_sigs = filter_signatures(sigs, groups)\n",
    "    print(f\"Kept {len(filtered_sigs)} of {len(sigs)} signatures\")\n",
    "    with open(\"../sigs_filtered.txt\", \"w\") as f:\n",
    "        for sig in filtered_sigs:\n",
    "            f.write(sig.hex() + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter groups with exposed WOTS secrets\n",
    "groups = {adrs: sigs \n",
    "    for adrs, sigs in groups.items()\n",
    "    if any(not sig.valid and shared_intermediates(sig, valid_sigs[adrs]) for sig in sigs)\n",
    "}\n",
    "print(f\"Found {len(groups)} groups with exposed WOTS secrets\")\n",
    "print_groups(pk_seed, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join WOTS keys to get a WOTS key usable for signing as many messages as possible\n",
    "from copy import deepcopy\n",
    "\n",
    "def join_sigs(wots_keys: dict[fips205.ADRS, set[fips205.WOTSKeyData]], params, pk_seed) -> dict[fips205.ADRS, fips205.WOTSKeyData]:\n",
    "    joined_sigs = {}\n",
    "    valid_sigs = valid_sigs_d(wots_keys)\n",
    "    for adrs, keys in wots_keys.items():\n",
    "        if len(keys) < 2:\n",
    "            continue\n",
    "        retval = deepcopy(valid_sigs[adrs])\n",
    "        if not retval.chains_calculated:\n",
    "            print_adrs(adrs)\n",
    "            retval.calculate_intermediates(params, adrs, pk_seed, valid_sigs[adrs])\n",
    "        for key in keys:\n",
    "            retval = retval.join(key, params)\n",
    "        joined_sigs[adrs] = retval\n",
    "    return joined_sigs\n",
    "\n",
    "joined_sigs = join_sigs(groups, params, pk_seed)\n",
    "print(f\"Joined {len(joined_sigs)} signatures\")\n",
    "\n",
    "\"\"\"\n",
    "for adrs, key in joined_sigs.items():\n",
    "    print_adrs(adrs, verbose=True)\n",
    "    print_key_data(key, adrs, pk_seed, None)\n",
    "\"\"\"\n",
    "\n",
    "# Filter out signatures with unresolved chains\n",
    "joined_sigs = {adrs: key for adrs, key in joined_sigs.items() if all(c < slh.w for c in key.chains_calculated)}\n",
    "\n",
    "print(f\"Filtered {len(joined_sigs)} (unresolved chains)\")\n",
    "\n",
    "# Filter out signatures with all chains set to 0\n",
    "#joined_sigs = {adrs: key for adrs, key in joined_sigs.items() if any(c > 0 for c in key.chains_calculated)}\n",
    "#print(f\"Filtered {len(joined_sigs)} (wildcard chains)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e12e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the key where the maximum number of chains are exposed (i.e., valid_sig.chain[i] - c is maximized for all chains 0 <= i < len)\n",
    "def score(key: fips205.WOTSKeyData) -> int:\n",
    "    return sum(slh.w - c for c in key.chains_calculated)\n",
    "most_exposed_adrs, most_exposed_key = max(\n",
    "    joined_sigs.items(),\n",
    "    key=lambda item: score(item[1]))\n",
    "print(\"Key with most exposed chains (score: {}):\".format(\n",
    "    score(most_exposed_key)\n",
    "))\n",
    "print_adrs(most_exposed_adrs, verbose=True)\n",
    "print_key_data(most_exposed_key, most_exposed_adrs, pk_seed, None)\n",
    "\n",
    "# try to sign the original message with the exposed key\n",
    "print(\"Signing original (valid) msg with exposed key...\")\n",
    "assert most_exposed_key.try_sign(most_exposed_key.chains, most_exposed_adrs, pk_seed, params)\n",
    "\n",
    "# signing message with same checksum\n",
    "# Find two offsets i, j where the chain is partially exposed\n",
    "exposed_offsets = [(idx, c - cc) for idx, (c, cc) in enumerate(zip(most_exposed_key.chains[:slh.len1], most_exposed_key.chains_calculated[:slh.len1])) if abs(c - cc) > 0]\n",
    "if len(exposed_offsets) >= 2:\n",
    "    i, j = exposed_offsets[:2]\n",
    "    print(f\"Found exposed offsets: i={i}, j={j}\")\n",
    "    chains = most_exposed_key.chains_calculated.copy()[:slh.len1]\n",
    "    chains[i[0]] += 1\n",
    "    print(\"Signing modified message with exposed key...\")\n",
    "    assert most_exposed_key.try_sign(chains, most_exposed_adrs, pk_seed, params)\n",
    "else:\n",
    "    print(\"Not enough exposed offsets found\")\n",
    "    \n",
    "# forge a signature\n",
    "msg = most_exposed_key.chains_calculated.copy()\n",
    "\n",
    "print(\"=\"*64)\n",
    "print(\"All keys for exposed address:\")\n",
    "print_adrs(most_exposed_adrs, verbose=True)\n",
    "for key in groups[most_exposed_adrs]:\n",
    "    print_key_data(key, most_exposed_adrs, pk_seed, valid_sigs[most_exposed_adrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc8602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of signinable messages (without checksum)\n",
    "import math\n",
    "\n",
    "\n",
    "def num_signable_messages(key: fips205.WOTSKeyData) -> int:\n",
    "    num_sign = 1\n",
    "    for i in range(slh.len1):\n",
    "        if key.chains_calculated[i] < slh.w - 1:\n",
    "            num_sign *= (slh.w - 1 - key.chains_calculated[i])\n",
    "    return num_sign/(slh.w-1)**slh.len1\n",
    "num_signable = num_signable_messages(most_exposed_key)\n",
    "expected_reps = 1/num_signable\n",
    "print(f\"Fraction of signable messages: {num_signable}\")\n",
    "print(f\"Expected number of repetitions until a valid signature is found: 2**{math.log2(expected_reps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6cef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign a random message with the exposed key\n",
    "msg = bytes.fromhex('bc9c6c7892ac9aa558a7ee5ef40a50bed3796a3cc657e88c6cedec7ddffbdad2')\n",
    "most_exposed_key.try_sign(msg, most_exposed_adrs, pk_seed, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c70dca9",
   "metadata": {},
   "source": [
    "# Tree Grafting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35878c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cryptanalysis_lib as clib\n",
    "import importlib\n",
    "importlib.reload(clib)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd56ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit clib.sign_worker((100, most_exposed_adrs, most_exposed_key, pk_seed, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98254039",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit clib.sign_worker_xmss((100, most_exposed_adrs, most_exposed_key, pk_seed, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc4511",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit clib.sign_worker_xmss_c((100, most_exposed_adrs, most_exposed_key, pk_seed, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10acdae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "from os import cpu_count\n",
    "\n",
    "import concurrent\n",
    "\n",
    "def sign_message_batch_mp(total_msgs, joined_sigs_items, pk_seed, params, num_procs=None):\n",
    "    \"\"\"\n",
    "    Use a process pool to sign `total_msgs` messages *per* (adrs,key).\n",
    "    Returns the first successful message signed by any process.\n",
    "    \"\"\"\n",
    "    if num_procs is None:\n",
    "        num_procs = cpu_count()\n",
    "\n",
    "    # Split total_msgs into roughly equal chunks per process\n",
    "    per_proc = math.ceil(total_msgs / num_procs)\n",
    "    print(\"Total messages per process:\", per_proc)\n",
    "\n",
    "    # Build one work item per (process x key)\n",
    "    work = []\n",
    "    for adrs, key in joined_sigs_items.items():\n",
    "        for _ in range(num_procs):\n",
    "            work.append((per_proc, adrs, key, pk_seed, params))\n",
    "    \n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        futures = {executor.submit(clib.sign_worker_xmss_c, work): work for work in work}\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result:\n",
    "                    print(\"Got result:\", result)\n",
    "                    # Cancel all other futures\n",
    "                    for f in futures:\n",
    "                        f.cancel()\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(\"Error:\", e)\n",
    "    return result\n",
    "\n",
    "if expected_reps > 2**29:\n",
    "    raise ValueError(\"Expected repetitions are too high, aborting\")\n",
    "num_sigs = 10\n",
    "\n",
    "print(f\"Signing {num_sigs} messages\")\n",
    "xmss_pk, adrs, sk, pk, key  = sign_message_batch_mp(num_sigs, {most_exposed_adrs: most_exposed_key}, pk_seed, params, num_procs=cpu_count()-1)\n",
    "print(\"Successfully grafted tree for XMSS PK \" + xmss_pk.hex())\n",
    "print(\"Address:\", adrs)\n",
    "print(\"SK seed:\", sk.hex())\n",
    "print(\"PK seed:\", pk.hex())\n",
    "print(\"Key:\", key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
